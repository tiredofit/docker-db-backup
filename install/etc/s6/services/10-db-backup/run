#!/usr/bin/with-contenv bash

date >/dev/null

if [ "$1" != "NOW" ]; then
    sleep 10
fi

### Set Debug Mode
if [ "$DEBUG_MODE" = "TRUE" ] || [ "$DEBUG_MODE" = "true" ]; then
    set -x
fi

### Sanity Test
if [ ! -n "$DB_TYPE" ]; then
    echo '** [db-backup] ERROR: No Database Type Selected! '
    exit 1
fi

if [ ! -n "$DB_HOST" ]; then
    echo '** [db-backup] ERROR: No Database Host Entered! '
    exit 1
fi

### Set Defaults
COMPRESSION=${COMPRESSION:-GZ}
PARALLEL_COMPRESSION=${PARALLEL_COMPRESSION:-TRUE}
DB_DUMP_FREQ=${DB_DUMP_FREQ:-1440}
DB_DUMP_BEGIN=${DB_DUMP_BEGIN:-+0}
DB_DUMP_TARGET=${DB_DUMP_TARGET:-/backup}
DBHOST=${DB_HOST}
DBNAME=${DB_NAME}
DBPASS=${DB_PASS}
DBUSER=${DB_USER}
DBTYPE=${DB_TYPE}
MD5=${MD5:-TRUE}
SPLIT_DB=${SPLIT_DB:-FALSE}
TMPDIR=/tmp/backups

if [ "$1" = "NOW" ]; then
    DB_DUMP_BEGIN=+0
    MANUAL=TRUE
fi

### Set Compression Options
if [ "$PARALLEL_COMPRESSION" = "TRUE " ]; then
    BZIP="pbzip2"
    GZIP="pigz"
    XZIP="pixz"
else
    BZIP="bzip2"
    GZIP="gzip"
    XZIP="xz"
fi


### Set the Database Type
       case "$DBTYPE" in
            "couch" | "couchdb" | "COUCH" | "COUCHDB"  )
            DBTYPE=couch
            DBPORT=${DB_PORT:-5984}
            ;;
            "influx" | "influxdb" | "INFLUX" | "INFLUXDB"  )
            DBTYPE=influx
            DBPORT=${DB_PORT:-8088}
            ;;
            "mongo" | "mongodb" | "MONGO" | "MONGODB" )
            DBTYPE=mongo
            DBPORT=${DB_PORT:-27017}
            [[ ( -n "${DB_USER}" ) ]] && MONGO_USER_STR=" --username ${DBUSER}"
            [[ ( -n "${DB_PASS}" ) ]] && MONGO_PASS_STR=" --password ${DBPASS}"
            [[ ( -n "${DB_NAME}" ) ]] && MONGO_DB_STR=" --db ${DBNAME}"
            ;;
            "mysql" | "MYSQL" | "mariadb" | "MARIADB")
            DBTYPE=mysql
            DBPORT=${DB_PORT:-3306}
            [[ ( -n "${DB_PASS}" ) ]] && MYSQL_PASS_STR=" -p${DBPASS}"
            ;;
            "postgres" | "postgresql" | "pgsql" | "POSTGRES" | "POSTGRESQL" | "PGSQL" )
            DBTYPE=pgsql
            DBPORT=${DB_PORT:-5432}
            [[ ( -n "${DB_PASS}" ) ]] && POSTGRES_PASS_STR="PGPASSWORD=${DBPASS}"
            ;;
            "redis" | "REDIS"   )
            DBTYPE=redis
            DBPORT=${DB_PORT:-6379}
            ;;
            "rethink" | "RETHINK"   )
            DBTYPE=rethink
            DBPORT=${DB_PORT:-28015}
            [[ ( -n "${DB_PASS}" ) ]] && echo $DB_PASS>/tmp/.rethink.auth; RETHINK_PASS_STR=" --password-file /tmp/.rethink.auth"
            [[ ( -n "${DB_NAME}" ) ]] && RETHINK_DB_STR=" -e ${DBNAME}"
            ;;
        esac

### Functions
function backup_couch() {
    TARGET=couch_${DBNAME}_${DBHOST}_${now}.txt
    curl -X GET http://${DBHOST}:${DBPORT}/${DBNAME}/ all docs? include docs=true >${TMPDIR}/${TARGET}
    generate_md5
    compression
    move_backup
}

function backup_mysql() {
    if [ "$SPLIT_DB" = "TRUE" ] || [ "$SPLIT_DB" = "true" ];  then   
        DATABASES=`mysql -h $DBHOST -u$DBUSER -p$DBPASS --batch -e "SHOW DATABASES;" | grep -v Database|grep -v schema`
        
        for db in $DATABASES; do
                if [[ "$db" != "information_schema" ]] && [[ "$db" != _* ]] ; then
                    echo "** [db-backup] Dumping database: $db"
                    TARGET=mysql_${db}_${DBHOST}_${now}.sql
                    mysqldump --max-allowed-packet=512M -h $DBHOST -u$DBUSER ${MYSQL_PASS_STR} --databases $db > ${TMPDIR}/${TARGET}
                    generate_md5
                    compression
                    move_backup
                fi
        done
    else
        mysqldump --max-allowed-packet=512M -A -h $DBHOST -u$DBUSER ${MYSQL_PASS_STR} > ${TMPDIR}/${TARGET}
        generate_md5
        compression
        move_backup
    fi
}

function backup_influx() {
    for DB in $DB_NAME; do
        influxd backup -database $DB -host ${DBHOST}:${DBPORT} ${TMPDIR}/${TARGET}
        generate_md5
        compression
        move_backup
    done
}

function backup_mongo() {
    mongodump --out ${TMPDIR}/${TARGET} --host ${DBHOST} --port ${DBPORT} ${MONGO_USER_STR}${MONGO_PASS_STR}${MONGO_DB_STR} ${EXTRA_OPTS}
    cd ${TMPDIR}
    tar cf ${TARGET}.tar ${TARGET}/*
    TARGET=${TARGET}.tar   
    generate_md5
    compression
    move_backup
}

function backup_pgsql() {
  if [ "$SPLIT_DB" = "TRUE" ] || [ "$SPLIT_DB" = "true" ];  then
      export PGPASSWORD=${DBPASS}
      DATABASES=`psql -h $DBHOST -U $DBUSER -p ${DBPORT} -c 'COPY (SELECT datname FROM pg_database WHERE datistemplate = false) TO STDOUT;' `
            for db in $DATABASES; do
                echo "** [db-backup] Dumping database: $db"
                TARGET=pgsql_${db}_${DBHOST}_${now}.sql
                pg_dump -h ${DBHOST} -p ${DBPORT} -U ${DBUSER} $db > ${TMPDIR}/${TARGET}
                generate_md5
                compression
                move_backup
            done
        else
            export PGPASSWORD=${DBPASS}
            pg_dump -h ${DBHOST} -U ${DBUSER} -p ${DBPORT} ${DBNAME} > ${TMPDIR}/${TARGET}
            generate_md5
            compression
            move_backup
  fi
}

function backup_redis() {
    TARGET=redis_${db}_${DBHOST}_${now}.rdb
    echo bgsave | redis-cli -h ${DBHOST} -p ${DBPORT} --rdb ${TMPDIR}/${TARGET}
    echo "** [db-backup] Dumping Redis - Flushing Redis Cache First"
    sleep 10
    try=5
    while [ $try -gt 0 ] ; do
        saved=$(echo 'info Persistence' | redis-cli -h ${DBHOST} -p ${DBPORT} | awk '/rdb_bgsave_in_progress:0/{print "saved"}')
        ok=$(echo 'info Persistence' | redis-cli -h ${DBHOST} -p ${DBPORT} | awk '/rdb_last_bgsave_status:ok/{print "ok"}')
        if [[ "$saved" = "saved" ]] && [[ "$ok" = "ok" ]]; then
            echo "** [db-backup] Redis Backup Complete"
        fi
        try=$((try - 1))
        echo "** [db-backup] Redis Busy - Waiting and retrying in 5 seconds"
        sleep 5
    done
    generate_md5
    compression
    move_backup
}

function backup_rethink() {
    TARGET=rethink_${db}_${DBHOST}_${now}.tar.gz  
    echo "** [db-backup] Dumping rethink Database: $db"
    rethinkdb dump -f ${TMPDIR}/${TARGET} -c ${DBHOST}:${DBPORT} ${RETHINK_PASS_STR} ${RETHINK_DB_STR}
    move_backup
}

function compression() {
   case "$COMPRESSION" in
        "GZ" | "gz" | "gzip" | "GZIP")
        $GZIP ${TMPDIR}/${TARGET}
        TARGET=${TARGET}.gz
        ;;
        "BZ" | "bz" | "bzip2" | "BZIP2" | "bzip" | "BZIP" | "bz2" | "BZ2")
        $BZIP ${TMPDIR}/${TARGET}
        TARGET=${TARGET}.bz2
        ;;
        "XZ" | "xz" | "XZIP" | "xzip" )
        $XZIP ${TMPDIR}/${TARGET}
        TARGET=${TARGET}.xz
        ;;
        "NONE" | "none" | "FALSE" | "false")
        ;;
    esac
}

function generate_md5() {
if [ "$MD5" = "TRUE" ] || [ "$MD5" = "true" ] ;  then  
    cd $TMPDIR
    md5sum ${TARGET} > ${TARGET}.md5
fi
}

function move_backup() {
    mkdir -p ${DB_DUMP_TARGET}
    mv ${TMPDIR}/*.md5 ${DB_DUMP_TARGET}/
    mv ${TMPDIR}/${TARGET} ${DB_DUMP_TARGET}/${TARGET}
}


### Container Startup  
echo '** [db-backup] Initialized at at '$(date)

### Wait for Next time to start backup
  current_time=$(date +"%s")
  today=$(date +"%Y%m%d")
  
  if [[ $DB_DUMP_BEGIN =~ ^\+(.*)$ ]]; then
        waittime=$(( ${BASH_REMATCH[1]} * 60 ))
  else
        target_time=$(date --date="${today}${DB_DUMP_BEGIN}" +"%s")
    if [[ "$target_time" < "$current_time" ]]; then
        target_time=$(($target_time + 24*60*60))
    fi
  waittime=$(($target_time - $current_time))
  fi

  sleep $waittime


### Commence Backup
  while true; do
    # make sure the directory exists
    mkdir -p $TMPDIR

### Define Target name
    now=$(date +"%Y%m%d-%H%M%S")
    TARGET=${DBTYPE}_${DBNAME}_${DBHOST}_${now}.sql

### Take a Dump
       case "$DBTYPE" in
        "couch" )
        backup_couch
        ;;
        "influx" )
        backup_influx
        ;;
        "mysql" )
        backup_mysql
        ;;
        "mongo" )
        backup_mongo
        ;;
        "pgsql" )
        backup_pgsql
        ;;
        "redis" )
        backup_redis
        ;;
        "rethink" )
        backup_rethink
        ;;
        esac

### Zabbix 
    if [ "$ENABLE_ZABBIX" = "TRUE" ] || [ "$ENABLE_ZABBIX" = "true" ];  then
        zabbix_sender -c /etc/zabbix/zabbix_agentd.conf -k dbbackup.size -o `stat -c%s ${DB_DUMP_TARGET}/${TARGET}`
        zabbix_sender -c /etc/zabbix/zabbix_agentd.conf -k dbbackup.datetime -o `date -r  ${DB_DUMP_TARGET}/${TARGET} +'%s'`
    fi
    
### Automatic Cleanup
    if [[ -n "$DB_CLEANUP_TIME" ]]; then
          find $DB_DUMP_TARGET/  -mmin +$DB_CLEANUP_TIME -iname "$DBTYPE_$DBNAME_*.*" -exec rm {} \;
    fi

    ### Go back to Sleep until next Backup time
    if [ "$MANUAL" = "TRUE" ]; then
        exit 1;
    else
        sleep $(($DB_DUMP_FREQ*60))
    fi

  done
fi
